{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71c75ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gemma-3-27b-it', created=None, object='model', owned_by='organization_owner'), Model(id='phi-3.5-vision-instruct', created=None, object='model', owned_by='organization_owner'), Model(id='text-embedding-nomic-embed-text-v1.5@q4_k_m', created=None, object='model', owned_by='organization_owner'), Model(id='llama-3.3-70b-instruct', created=None, object='model', owned_by='organization_owner'), Model(id='qwen2-7b-instruct', created=None, object='model', owned_by='organization_owner'), Model(id='meta-llama-3.1-70b-instruct', created=None, object='model', owned_by='organization_owner'), Model(id='mistral-7b-instruct-v0.3', created=None, object='model', owned_by='organization_owner'), Model(id='llama-3-8b-instruct-64k', created=None, object='model', owned_by='organization_owner'), Model(id='gemma-2-27b-it', created=None, object='model', owned_by='organization_owner'), Model(id='meta-llama-3.1-8b-instruct', created=None, object='model', owned_by='organization_owner'), Model(id='gemma-2-9b-it', created=None, object='model', owned_by='organization_owner'), Model(id='deepseek-r1-distill-qwen-14b', created=None, object='model', owned_by='organization_owner'), Model(id='text-embedding-nomic-embed-text-v1.5@q8_0', created=None, object='model', owned_by='organization_owner')], object='list')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8303e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to 'representative_votes_clean_format_images_exist.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"representative_votes_clean_format.csv\")\n",
    "\n",
    "# Rename Unnamed: 0 → case_ID if it exists\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df.rename(columns={\"Unnamed: 0\": \"case_ID\"}, inplace=True)\n",
    "\n",
    "# Define image folder\n",
    "image_dir = \"gsv/final_photo_dataset\"\n",
    "\n",
    "# Function to check if an image file exists (with any common extension)\n",
    "def has_image(image_id):\n",
    "    for ext in [\".JPG\", \".jpg\", \".jpeg\"]:\n",
    "        if os.path.exists(os.path.join(image_dir, f\"{image_id}{ext}\")):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Filter rows where both left and right images exist\n",
    "df[\"left_exists\"] = df[\"left\"].astype(str).apply(has_image)\n",
    "df[\"right_exists\"] = df[\"right\"].astype(str).apply(has_image)\n",
    "\n",
    "# Keep only rows where both exist\n",
    "df_cleaned = df[df[\"left_exists\"] & df[\"right_exists\"]].copy()\n",
    "\n",
    "# Drop helper columns\n",
    "df_cleaned.drop(columns=[\"left_exists\", \"right_exists\"], inplace=True)\n",
    "\n",
    "# Save result\n",
    "df_cleaned.to_csv(\"representative_votes_clean_format_images_exist.csv\", index=False)\n",
    "print(\"✅ Saved to 'representative_votes_clean_format_images_exist.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e6c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged images saved to 'merged_images/'\n",
      "✅ Metadata saved to 'merged_metadata.csv'\n",
      "⚠️ Missing or error rows:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"representative_votes_clean_format_images_exist.csv\")\n",
    "\n",
    "image_dir = \"gsv/final_photo_dataset\"\n",
    "output_dir = \"merged_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "separator_width = 100\n",
    "separator_color = (255, 255, 255)\n",
    "\n",
    "def get_image_path(base_name):\n",
    "    for ext in [\".JPG\", \".jpg\", \".jpeg\"]:\n",
    "        path = os.path.join(image_dir, f\"{base_name}{ext}\")\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "# Track metadata\n",
    "matched_rows = []\n",
    "missing_logs = []\n",
    "\n",
    "merged_index = 0\n",
    "row_idx = 0\n",
    "\n",
    "while merged_index < 100 and row_idx < len(df):\n",
    "    row = df.iloc[row_idx]\n",
    "    row_idx += 1\n",
    "\n",
    "    left_id = str(row[\"left\"])\n",
    "    right_id = str(row[\"right\"])\n",
    "\n",
    "    left_path = get_image_path(left_id)\n",
    "    right_path = get_image_path(right_id)\n",
    "\n",
    "    if not left_path or not right_path:\n",
    "        if not left_path:\n",
    "            missing_logs.append(f\"Row {row_idx - 1}: Missing left image '{left_id}'\")\n",
    "        if not right_path:\n",
    "            missing_logs.append(f\"Row {row_idx - 1}: Missing right image '{right_id}'\")\n",
    "        continue  # Skip this row\n",
    "\n",
    "    try:\n",
    "        left_img = Image.open(left_path)\n",
    "        right_img = Image.open(right_path)\n",
    "\n",
    "        max_height = max(left_img.height, right_img.height)\n",
    "        left_img = ImageOps.pad(left_img, (left_img.width, max_height))\n",
    "        right_img = ImageOps.pad(right_img, (right_img.width, max_height))\n",
    "\n",
    "        separator = Image.new(\"RGB\", (separator_width, max_height), separator_color)\n",
    "\n",
    "        merged = Image.new(\"RGB\", (left_img.width + separator_width + right_img.width, max_height))\n",
    "        merged.paste(left_img, (0, 0))\n",
    "        merged.paste(separator, (left_img.width, 0))\n",
    "        merged.paste(right_img, (left_img.width + separator_width, 0))\n",
    "\n",
    "        filename = f\"merged_{merged_index:03d}.jpg\"\n",
    "        merged.save(os.path.join(output_dir, filename))\n",
    "\n",
    "        matched_rows.append({\n",
    "            \"merged_index\": merged_index,\n",
    "            \"row_index\": row[\"case_ID\"],\n",
    "            \"left\": left_id,\n",
    "            \"right\": right_id,\n",
    "            \"study_question\": row[\"study_question\"],\n",
    "            \"choice\": row[\"choice\"],\n",
    "            \"place_name_left\":row[\"place_name_left\"],\n",
    "            \"place_name_right\":row[\"place_name_right\"],\n",
    "            \"left_vote\":row[\"left_num\"],\n",
    "            \"right_vote\":row[\"right_num\"]\n",
    "        })\n",
    "\n",
    "        merged_index += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        missing_logs.append(f\"Row {row_idx - 1}: ERROR during merge: {e}\")\n",
    "\n",
    "# Save metadata\n",
    "pd.DataFrame(matched_rows).to_csv(\"merged_metadata.csv\", index=False)\n",
    "\n",
    "# Print missing log\n",
    "print(\"✅ Merged images saved to 'merged_images/'\")\n",
    "print(\"✅ Metadata saved to 'merged_metadata.csv'\")\n",
    "print(\"⚠️ Missing or error rows:\")\n",
    "for log in missing_logs:\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"representative_votes_clean_format_images_exist.csv\")\n",
    "\n",
    "image_dir = \"gsv/final_photo_dataset\"\n",
    "output_dir = \"merged_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "separator_width = 100\n",
    "separator_color = (255, 255, 255)\n",
    "\n",
    "def get_image_path(base_name):\n",
    "    for ext in [\".JPG\", \".jpg\", \".jpeg\"]:\n",
    "        path = os.path.join(image_dir, f\"{base_name}{ext}\")\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "# Track metadata\n",
    "matched_rows = []\n",
    "missing_logs = []\n",
    "\n",
    "merged_index = 0\n",
    "row_idx = 0\n",
    "\n",
    "for merged_index, row in df.iterrows():\n",
    "    row = df.iloc[row_idx]\n",
    "    row_idx += 1\n",
    "\n",
    "    left_id = str(row[\"left\"])\n",
    "    right_id = str(row[\"right\"])\n",
    "\n",
    "    left_path = get_image_path(left_id)\n",
    "    right_path = get_image_path(right_id)\n",
    "\n",
    "    if not left_path or not right_path:\n",
    "        if not left_path:\n",
    "            missing_logs.append(f\"Row {row_idx - 1}: Missing left image '{left_id}'\")\n",
    "        if not right_path:\n",
    "            missing_logs.append(f\"Row {row_idx - 1}: Missing right image '{right_id}'\")\n",
    "        continue  # Skip this row\n",
    "\n",
    "    try:\n",
    "        left_img = Image.open(left_path)\n",
    "        right_img = Image.open(right_path)\n",
    "\n",
    "        max_height = max(left_img.height, right_img.height)\n",
    "        left_img = ImageOps.pad(left_img, (left_img.width, max_height))\n",
    "        right_img = ImageOps.pad(right_img, (right_img.width, max_height))\n",
    "\n",
    "        separator = Image.new(\"RGB\", (separator_width, max_height), separator_color)\n",
    "\n",
    "        merged = Image.new(\"RGB\", (left_img.width + separator_width + right_img.width, max_height))\n",
    "        merged.paste(left_img, (0, 0))\n",
    "        merged.paste(separator, (left_img.width, 0))\n",
    "        merged.paste(right_img, (left_img.width + separator_width, 0))\n",
    "\n",
    "        filename = f\"merged_{merged_index:03d}.jpg\"\n",
    "        merged.save(os.path.join(output_dir, filename))\n",
    "\n",
    "        matched_rows.append({\n",
    "            \"merged_index\": merged_index,\n",
    "            \"row_index\": row[\"case_ID\"],\n",
    "            \"left\": left_id,\n",
    "            \"right\": right_id,\n",
    "            \"study_question\": row[\"study_question\"],\n",
    "            \"choice\": row[\"choice\"],\n",
    "            \"place_name_left\":row[\"place_name_left\"],\n",
    "            \"place_name_right\":row[\"place_name_right\"],\n",
    "            \"left_vote\":row[\"left_num\"],\n",
    "            \"right_vote\":row[\"right_num\"]\n",
    "        })\n",
    "\n",
    "        merged_index += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        missing_logs.append(f\"Row {row_idx - 1}: ERROR during merge: {e}\")\n",
    "\n",
    "# Save metadata\n",
    "pd.DataFrame(matched_rows).to_csv(\"merged_metadata.csv\", index=False)\n",
    "\n",
    "# Print missing log\n",
    "print(\"✅ Merged images saved to 'merged_images/'\")\n",
    "print(\"✅ Metadata saved to 'merged_metadata.csv'\")\n",
    "print(\"⚠️ Missing or error rows:\")\n",
    "for log in missing_logs:\n",
    "    print(log)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
